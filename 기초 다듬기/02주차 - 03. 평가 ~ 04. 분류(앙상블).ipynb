{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3 평가\n",
    "\n",
    "앞에서는 모델 예측 성능의 평가를 위해 정확도(Accuracy)를 이용했다. 하지만 이 밖에도 여러 가지 방법으로 예측 성능을 평가할 수 있다. <br/> 성능 평가 모델은 일반적으로 모델이 분류냐 회귀냐에 따라 다르다. <br/> 분류의 성능 평가 지표는 다음과 같다.\n",
    "- 정확도(Accuracy)\n",
    "- 오차행렬(Confusion Matrix0\n",
    "- 정밀도(Precision)\n",
    "- 재현율(Recall)\n",
    "- F1 스코어\n",
    "- ROC AUC\n",
    "\n",
    "분류의 경우 결정 클래스 값 종류의 유형에 따라 이진 분류와 선택 분류로 나뉠 수 있다. 위의 지표들은 모두 적용되는 지표이지만  특히 이진 분류에서 더욱 중요하게 강조하는 지표이다.\n",
    "\n",
    "### 1. 정확도(Accuracy)\n",
    "\n",
    "정확도는 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표이며 전체 예측 데이터 건수에서 예측 결과가 동일한 데이터 건수의 비율이다. 직관적으로 모델 예측 성능을 나타낸다. 하지만 불균형한 데이터에 의한 정확도의 착시 현상에 속지 않도록, 특히 이진 판단일 경우 주의해야 한다.\n",
    "\n",
    "### 2. 오차 행렬\n",
    "\n",
    "이진 분류에서 성능 지표로 잘 활용되는 오차 행렬(confusion matrix, 혼동행렬)은 학습된 분류 모델이 예측을 수행하면성 얼마나 핫갈려하는지도 함께 보여주는 지표이다.\n",
    "\n",
    "![오차 행렬](./images/confusionMatrix.png)\n",
    "\n",
    "위의 TN, FP, FN, TP로 각 4분면을 채우고 이를 다양하게 결합해 분류 모델 성능의 오류가 어떠한 모습으로 발생하는 지 알 수 있다. <br/> 사이킷런 역시 이를 위한 API를 제공한다.\n",
    "\n",
    "```python\n",
    "from sklearn.metricx import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, pred)\n",
    "```\n",
    "\n",
    "이렇게 하면 반환값으로 각 행렬에 위치하는 값의 수가 2차원 리스트로 반환된다.\n",
    "\n",
    "### 3. 정밀도와 재현율\n",
    "\n",
    "정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표이다.\n",
    "- 정밀도 = TP / (FP + TP)\n",
    "- 재현율 = TP / (FN + TP)\n",
    "\n",
    "정밀도는 예측을 긍정으로 한 대상 중 실제 값이 긍정으로 일치한 데이터의 비율이다. <br/> 재현율은 실제 값이 긍정인 대상 중 예측과 실제 값이 긍정으로 일치한 데이터의 비율이다. <br/> 각각 업무 특성에 따라 특정 지표가 더 중요한 지표로 간주될 수 있다.\n",
    "\n",
    "- 재현율이 더 중요한 경우 : 실제 긍정인 예측을 부정으로 잘못 판단하면 업무상 큰 영향을 끼치는 경우\n",
    "- 정밀도가 더 중요한 경우 : 실제 부정인 예측을 긍정으로 잘못 판단하면 업무상 큰 영향을 끼치는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차 행렬 및 정밀도, 재현율을 모두 구하는 함수를 만들어보자.\n",
    "# 사이킷런은 정밀도 계산을 위해 precision_score()를,\n",
    "# 재현율 계산을 위해 recall_score()를 제공한다.\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred) :\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도 : {0:.4f}, 정밀도 : {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도 : 0.8492, 정밀도 : 0.7742, 재현율: 0.7869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korea_1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 타이타닉 생존자 예측 후 위 함수를 실행시켜 보자.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# 이전에 타이타닉 전처리때 만든 함수들\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 분할\n",
    "titanic_df = pd.read_csv('./data/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                  test_size=0.2, random_state=0)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \\\n",
    "                                                    test_size=0.20, random_state=11)\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "lr_clf.fit(X_train , y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "get_clf_eval(y_test , pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정밀도/재현율 트레이드 오프\n",
    "\n",
    "정밀도와 재현율은 상호 보완적인 평가지표이기 때문에 하나를 높이면 하나는 낮아지기 쉽다. 이런 사이를 trade off라고 한다. <br/><br/> 사이킷런의 분류 알고리즘은 예측 데이터가 특정 레이블에 속하는지를 계산하기 위해 먼저 개별 레이블별로 결정 확률을 구한다. 그리고 예측 확률이 큰 레이블값으로 예측하게 된다. 사이킷런은 개별 데이터별로 예측 확률을 반환하는 predict_proba()를 제공한다. 테스트 피처 데이터 세트를 파라미터로 입력하면 테스트 피처 레코드의 개별 클래스 예측 확률을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_proba() 결과 shape : (179, 2)\n",
      "pred_proba() array에서 앞 3개만 샘플로 추출 \n",
      " : [[0.46170212 0.53829788]\n",
      " [0.87864222 0.12135778]\n",
      " [0.87728507 0.12271493]]\n",
      "두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \n",
      " [[0.46170212 0.53829788 1.        ]\n",
      " [0.87864222 0.12135778 0.        ]\n",
      " [0.87728507 0.12271493 0.        ]]\n",
      "0번째 칼럼이 0확률 1번째 칼럼이 1확률\n"
     ]
    }
   ],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)\n",
    "pred = lr_clf.predict(X_test)\n",
    "print('pred_proba() 결과 shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba() array에서 앞 3개만 샘플로 추출 \\n :', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array와 예측 결과값 array를 병합(concatenate)해 예측 확률과 결과 값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
    "print('두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])\n",
    "print('0번째 칼럼이 0확률 1번째 칼럼이 1확률')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정밀도와 재현율의 맹점\n",
    "\n",
    "Positive 예측의 임곗값을 변경함에 따라 정밀도와 재현율의 수치가 변경된다. 임곗값의 이러한 변경은 업무 환경에 맞게 두 개의 수치를 상호 보완할 수 있는 수준에서 적용되어야 한다. 하나만 극단적으로 높이면 안된다.\n",
    "\n",
    "##### 정밀도 100%가 되는 방법\n",
    "\n",
    "확실한 기준이 되는 경우만 긍정 예측, 나머지는 부정 예측 1000명 중 진짜 확실한 1명만 암환자 긍정 예측을 하고 나머진 다 부정 예측 시 100%\n",
    "\n",
    "##### 재현율 100%가 되는 방법\n",
    "\n",
    "모든 환자를 긍정 예측\n",
    "\n",
    "### 4. F1 스코어\n",
    "\n",
    "![f1score](./images/f1score.png)\n",
    "\n",
    "F1 스코어는 정밀도와 재현율을 결합한 지표이다. 정밀도와 재현율이 어느 한 쪽으로 치우치지 않는 수치를 나타낼 때 상대적으로 높은 값을 가집니다.<br/> 사이킷런에서도 이를 위한 API를 제공한다.\n",
    "```python\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, pred)\n",
    "print('F1 스코어 : {0:.4f}'.format(f1))\n",
    "```\n",
    "\n",
    "### 5. ROC 곡선과 AUC\n",
    "\n",
    "![roc](./images/ROC.png)\n",
    "\n",
    "ROC 곡선과 이에 기반한 AUC 스코어는 이진 분류의 예측 성능 측정에서 중요하게 사용되는 지표이다. ROC 곡선은 우리말로 수신자 판단 곡선으로 불린다. <br/> ROC 곡선은 FPR(False Positive Rate)가 변할 때 TPR(True Positive Rate)가 어떻게 변하는지를 나타내는 곡선이다. FPR을  X축으로 TPR을 Y축으로 잡으면 FPR의 변화에 따른 TPR의 변화가 곡선 형태로 나타난다. <br/>TPR은 곧 재현율이다. 이는 곧 민감도로도 불리며 이에 대응하는 지표로 TNR(True Negative Rate)라고 불리는 특이성이 있다. 특이성은 다음과 같이 구할 수 있다. <br/><br/>FPR = FP / (FP + TN) = 1 - TNR = 1 - 특이성 <br/><br/> ROC 곡선은 직선에 가까울수록 성능이 떨어지는 것이며 멀어질수록 성능이 뛰어난 것이다. <br/> ROC 곡선은 FPR을 0부터 1까지 변경하면서 TPR의 변화 값을 구한다. FPR을 0부터 1까지 변경하는 방법은 분류 결정 임곗값을 변경하는 것이다. (predict 에서의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
