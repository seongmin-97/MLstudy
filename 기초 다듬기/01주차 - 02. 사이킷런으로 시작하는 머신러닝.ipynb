{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2 사이킷런으로 시작하는 머신러닝\n",
    "\n",
    "### 1. 사이킷런 소개와 특징\n",
    "\n",
    "사이킷런(sckit-learn) : 파이썬 머신러닝 라이브러리 중 가장 많이 이용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 첫 번째 머신러닝 만들어보기 - 붓꽃 품종 예측\n",
    "### 3. 사이킷런의 기반 프레임워크 익히기\n",
    "\n",
    "- Estimator 이해 및 fit(), predict() 메서드 <br/> ML 모델 학습을 위해 fit(), predict() 메서드가 제공된다. 사이킷런에서는 분류 알고리즘을 구현한 클래스로 Classifier로, 회귀 알고리즘을 구현한 클래스를 Regressor로 지칭한다. 이들을 합쳐 Estimator라고 한다. <br/> 비지도 학습에서도 fit()과 transform()을 적용한다. 비지도 학습에서의 fit()은 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조를 맞추는 작업이고 transform()은 fit() 이후에 입력 데이터의 차원 변환, 클러스터링, 피처 추출 등의 실제 작업을 수행한다.\n",
    "- 사이킷런의 주요 모델 <br/> 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Selection 모듈 소개\n",
    "\n",
    "- 학습/테스트 데이터 세트 분리 : train_test_split() <br/>예측을 수행할 데이터 세트는 학습에 이용되지 않은 데이터여야 한다. train_test_split()으로 원본 데이터 세트를 학습/테스트 데이터 세트로 쉽게 분리할 수 있다. <br/>train_test_split() 은 첫 파라미터로 피처 데이터 세트, 두 번째 파라미터로 레이블 데이터 세트를 입력받는다. 선택적 파라미터는 다음과 같다.\n",
    "    - test_size : 전체 데이터에서 테스트 데이터 크기를 얼마로 할 지 결정한다. 기본 값은 0.25 (최대 1)\n",
    "    - train_size : 전체 데이터에서 학습 데이터 크기를 얼마로 할 지 결정한다. test_size가 있어 잘 사용하진 않음\n",
    "    - shuffle : 데이터를 분리하기 전 섞을지 말지를 결정. 디폴트는 True\n",
    "    - ramdom_state : 같은 결과가 필요할 때 같은 ramdom_state 값을 입력해야 함\n",
    "    \n",
    "반환 값은 튜플 형태이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도: 0.9556\n"
     ]
    }
   ],
   "source": [
    "# model selection 모듈 \n",
    "# 학습/테스트 데이터 세트 분리 - train_test_split()\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris_data = load_iris()\n",
    "df_clf = DecisionTreeClassifier()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)\n",
    "\n",
    "df_clf.fit(X_train, y_train)\n",
    "pred = df_clf.predict(X_test)\n",
    "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 검증\n",
    "<br/> 알고리즘 학습에는 학습 데이터와 예측 성능 평가를 위한 테스트용 데이터가 필요한데 이 역시 과적합에 취약하다. 이를 개선하기 위해 교차 검증을 이용해 더 다양한 학습과 평가를 수행한다. <br/>교차 검증은 데이터 편중을 막기 위해 학습 데이터 세트를 다시 학습 데이터와 검증 데이터로 나눈다. 그 후 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것이다. <br/>대부분의 ML 모델의 성능 평가는 교차 겁증 기반으로 1차 평가를 한 뒤 테스트 데이터 세트에 적용해 평가하는 프로세스이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K 폴드 교차 검증 \n",
    "\n",
    "가장 보편적으로 사용되는 교차 검증 기법이다. k개의 데이터 폴드 세트를 만들어 k번 만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법이다.\n",
    "![image.png](./images/KFold.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붗꽃 데이터 세트 크기 150\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증\n",
    "# k 폴드 교차 검증\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits=5)\n",
    "cv_accuracy = []\n",
    "print('붗꽃 데이터 세트 크기', features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
      "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "## 평균 검증 정확도: 0.9\n"
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "\n",
    "# KFold객체의 split( ) 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환  \n",
    "for train_index, test_index  in kfold.split(features):\n",
    "    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    #학습 및 예측 \n",
    "    dt_clf.fit(X_train , y_train)    \n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "    # 반복 시 마다 정확도 측정 \n",
    "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n",
    "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stratified K 폴드 \n",
    "불균형한 분포도를 가진 레이블 데이터 집합을 위한 K 폴드 방식 (ex) 대출 사기 감지 등) <br/> K폴드의 경우 폴드 세트로 나누면서 레이블 균형이 무너질 수 있다. <br/> 사용법은 K폴드와 비슷하지만 레이블 데이터 세트가 필수적으로 필요하다. (K 폴드의 경우 필수적이진 않음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##교차 검증: 1\n",
      "학습 레이블 데이터 분포:\n",
      " 2    34\n",
      "1    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 1    17\n",
      "0    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "##교차 검증: 2\n",
      "학습 레이블 데이터 분포:\n",
      " 1    34\n",
      "2    33\n",
      "0    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    17\n",
      "0    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "##교차 검증: 3\n",
      "학습 레이블 데이터 분포:\n",
      " 0    34\n",
      "2    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      " 2    17\n",
      "1    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index, test_index in skf.split(iris_df, iris_df['label']) :\n",
    "    n_iter += 1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('##교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
      "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
      "\n",
      "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
      "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
      "\n",
      "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
      "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
      " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      " 교차 검증별 정확도 :  [0.98 0.94 0.98]\n",
      "## 평균 검증 정확도 :  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "features = iris.data\n",
    "label = iris.target\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "# StratifiedKFold의 split() 호출 시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
    "for train_index, test_index in skfold.split(features, label) :\n",
    "    #split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    # 반복 시마다 정확도 측정\n",
    "    n_iter += 1\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
    "          .format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "# 교차 검증별 정확도 및 평균 정확도 계산\n",
    "print('\\n 교차 검증별 정확도 : ', np.round(cv_accuracy, 4))\n",
    "print('## 평균 검증 정확도 : ', np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 교차 검증을 보다 간편하게 - cross_val_score() \n",
    "사이킷런은 교차 검증을 좀 더편리하게 수행할 수 있게 API를 제공한다. 대표적인 것이 cross_val_score()이다. <br/> 직전 코드처럼 반복문을 쓸 필요가 없어진다. 원형은 다음과 같다.\n",
    "\n",
    "> cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
    "\n",
    "이 중 estimator, X, y, scoring, cv가 주요 파라미터이다.\n",
    "- estimator : Classifier 또는 Regressor를 의미\n",
    "- X : 피처 데이터 세트\n",
    "- y : 레이블 데이터 세트\n",
    "- scoring : 예측 성능 평가 지표\n",
    "- cv : 교차 검증 폴드 수\n",
    "- 반환값 : scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환\n",
    "- classifier가 입력되면 StratifiedKFold, 회귀인 경우 K폴드 방식으로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도:  [0.98 0.94 0.98]\n",
      "평균 검증 정확도 :  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
    "print('교차 검증별 정확도: ', np.round(scores, 4))\n",
    "print('평균 검증 정확도 : ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV - 교차 검증과 하이퍼 파라미터 튜닝을 한 번에\n",
    "\n",
    "GridSearchCV는 Classifier나 Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {'max_depth' : {1, 2, 3},\n",
    "                   'min_samples_split' : [2, 3]\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 경우 총 6회에 걸쳐 파라미터를 순차적으로 바꿔 실행한다. ((1, 2), (1, 3), (2, 1) ... (3, 3)) <br/> GridSearchCV는 교차 검증을 기반으로 이 하이퍼 파라미터의 최적 값을 찾게 해준다. 하지만 상대적으로 시간이 오래 걸린다. <br/> 위의 경우 cv가 3회라면 총 18회의 학습/평가가 진행된다. <br/> 주요 파라미터는 다음과 같다.\n",
    "- estiimator : classifier, regressor, pipeline이 사용될 수 있다.\n",
    "- param_grid : key + 리스트 값을 가지는 딕셔너리가 주어딘다. estimator 튜닝을 위해 파라미터명과 사용되 ㅍ여러 파라미터 값을 지정한다.\n",
    "- scoring : 예측 성능을 측정할 평가 방법을 지정한다. 별도의 성능 평가 지표 함수 지정 가능하다.\n",
    "- cv : 교차 검증을 위해 분할되는 학습/테스트 세트의 개수 지정\n",
    "- refit : 디폴트가 True이며 True로 생성 시 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                    test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터를 딕셔너리로 저장\n",
    "parameters = {'max_depth' : [1, 2, 3], 'min_samples_split' : [2, 3]}\n",
    "\n",
    "# param_grid의 하이퍼 파라미터를 3 개의 train, test set fold로 나누어 테스트 수행 설정\n",
    "# refit은 True가 디폴트 (가장 좋은 파라미터 설정으로 재학습) \n",
    "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
    "\n",
    "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score',\n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터 :  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도 : 0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터 : ', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도 : {0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# best_estimator_는 이미 최적 학습이 된 상태, 별도 학습 필요 없음\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도 : {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 데이터 전처리\n",
    "\n",
    "데이터 전처리는 ML 알고리즘만큼 중요하다. 결손값은 허용되지 않기에 이를 어떤 값으로 채워야 한다. <br/>만약 Null 값이 얼마 없다면 피처의 평균값 등으로 대체할 수 있지만 너무 많다면 drop하는 것도 좋다. <br/>가장 힘든 경우가 일정 수준 이상인 경우인데 정확한 기준은 없다. 하지만 해당 피처가 중요도가 높고 평균값으로 대체할 경우 왜곡이 심하다면 더 정밀한 대체값을 선정해야 한다. <br/><br/> 또 머신러닝 알고리즘에 문자열 값을 입력할 수 없으므로 문자열은 인코딩해서 숫자형으로 변환해야 한다. 불필요한 피처는 인코딩하지 않고 삭제하는 것이 좋다.\n",
    "\n",
    "#### 데이터 인코딩\n",
    "\n",
    "대표적으로 레이블 인코딩과 원-핫 인코딩이 있다.\n",
    "\n",
    "![image.png](./images/encoding.jpg)\n",
    "\n",
    "- 레이블 인코딩 <br/> 카티게로 피처를 코드형 숫자 값으로 변환하는 것이다. 예를 들면 TV: 1, 냉장고: 2, 전자레인지: 3, 컴퓨터: 4, 선풍기: 5, 믹서 6 과 같은 방식이다. <br/> 몇몇 ML 알고리즘에서 예측 성능을 저하시킨다. 이는 숫자 값의 크고 작음에 대한 특성이 작용하기 때문이다. 이러한 특성 때문에 레이블 인코딩은 선형 회귀와 같은 알고리즘에 작동시키면 안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환값:  [0 1 4 5 3 3 2 2]\n",
      "인코딩 클래스 ;  ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
      "디코딩 원본값 :  ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabaelEncoder 객체를 생성한 후 fit()과 transform()으로 레이블 인코딩 수행\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print('인코딩 변환값: ', labels)\n",
    "# 문자열 값이 어떤 숫자 값으로 인코딩됐는지 확인\n",
    "print('인코딩 클래스 ; ', encoder.classes_)\n",
    "# 디코딩 역시 가능하다.\n",
    "print('디코딩 원본값 : ', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원-핫 인코딩<br/>원-핫 인코딩은 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당되는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터 차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "# 2차원 데이터로 변환\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "# 원 핫 인코딩 적용\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "print('원-핫 인코딩 데이터 차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 판다스에서도 원-핫 인코딩을 쉽게 할 수 있도록 지원한다.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'item' : ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 피처 스케일링과 정규화\n",
    "\n",
    "서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업을 피처 스케일링이라고 한다. 대표적인 방법으로 표준화와 정규화가 있다.\n",
    "\n",
    "- 표준화 <br/>표준화는 데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것을 의미한다. \n",
    "- 정규화 <br/>정규화는 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념이다. 예를 들어 피처 a가 거리를 나타내는 변수로 0 ~ 100KM의 값이 주어지고, B는 금액을 나타내는 속성으로 값이 0 ~ 1000억원이라면 이 변수를 모두 동일한 크기 단위로 비교하기 위해 값을 모두 최소 0 ~ 최대 1로 변환하는 것이다.\n",
    "\n",
    "##### StandardScaler\n",
    "\n",
    "표준화를 쉽게 지원하기 위한 클래스이다. 즉, 개별 피처를 평균이 0이고 분산이 1인 갑승로 변환해준다. SVM, 선형 회귀, 로지스틱 회귀는 가우시안 분포를 가지고 있다고 가정하고 구현되었기에 사전에 표준화를 적용하는 것이 중요한 요소이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균 값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "# 붓꽃 데이터 세트 로딩하고 DataFrame으로 반환\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "\n",
    "print('feature들의 평균 값')\n",
    "print(iris_df.mean())\n",
    "print('\\nfeature들의 분산 값')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "# StandardScaler로 데이터 세트 변환. fit()과 transform() 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform() 시 스케일 변환된 데이터 세트가 ndarray로 반환되어 이를 DataFrame으로 저장\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature들의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "print('\\nfeature들의 분산 값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MinMaxScaler\n",
    "\n",
    "MinMaxScaler는 데이터값을 0과 1 사이의 범위값으로 변환한다. (음수 값이 있으면 -1에서 1값으로 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature들의 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "# MinMaxScaler로 데이터 세트 변환. fit()과 transform() 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform() 시 스케일 반환 된 ndarrary를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
    "print('feature들의 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature들의 최댓값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점\n",
    "\n",
    "Scaler 객체를 이용해 데이터의 스케일링 변환 시 fit(), transform(), fit_transform() 메소드를 이용한다.<br/>일반적으로 fit()은 데이터 변환을 위한 기준 정보 설정을 적용하며 transform()은 이렇게 설정된 정보를 이용해 데이터를 반환한다. fit_transform()은 이 둘을 한 번에 적용한다. <br/> 테스트 데이터에 대해서는 fit()하지 않는 것이 중요하다. 반드시 테스트 데이터는 학습 데이터의 스케일링 기준에 따라야 한다. 따라서 fit_transform() 역시 테스트 데이터에는 사용하면 안된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 사이킷런으로 수행하는 타이타닉 생존자 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "titanic_df = pd.read_csv('./data/titanic_train.csv')\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### 학습 데이터 정보 ### \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('\\n ### 학습 데이터 정보 ### \\n')\n",
    "print(titanic_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 세트 Null 개수 :  0\n"
     ]
    }
   ],
   "source": [
    "# Age는 Null값을 평균으로 채우고, Cabin, Embarked는 N으로 채움\n",
    "\n",
    "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
    "titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "titanic_df['Embarked'].fillna('N', inplace=True)\n",
    "print('데이터 세트 Null 개수 : ', titanic_df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex 값 분포 : \n",
      " male      577\n",
      "female    314\n",
      "Name: Sex, dtype: int64\n",
      "\n",
      " Cabin 값 분포 : \n",
      " N              687\n",
      "C23 C25 C27      4\n",
      "B96 B98          4\n",
      "G6               4\n",
      "F2               3\n",
      "              ... \n",
      "E31              1\n",
      "C101             1\n",
      "D48              1\n",
      "D10 D12          1\n",
      "C104             1\n",
      "Name: Cabin, Length: 148, dtype: int64\n",
      "\n",
      " Embarked 값 분포 ; \n",
      " S    644\n",
      "C    168\n",
      "Q     77\n",
      "N      2\n",
      "Name: Embarked, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 문자열 피처는 Sex, Cabin, Embarked 이다. 이 피처들의 값의 분류를 살피자\n",
    "\n",
    "print('Sex 값 분포 : \\n', titanic_df['Sex'].value_counts())\n",
    "print('\\n Cabin 값 분포 : \\n', titanic_df['Cabin'].value_counts())\n",
    "print('\\n Embarked 값 분포 ; \\n', titanic_df['Embarked'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    687\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "T      1\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 다른 것은 큰 문제가 없는데, Cabin의 경우 N이 687로 압도적이다.\n",
    "# 그런데 데이터를 보면 앞의 알파벳이 중요해 보이므로 이를 토대로 정리해보자.\n",
    "\n",
    "titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]\n",
    "titanic_df['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Survived\n",
       "female  0            81\n",
       "        1           233\n",
       "male    0           468\n",
       "        1           109\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영화에서 구조 순서 : 여성 아이들 노약자 다음으로 부자, 유명인\n",
    "# 일단 성별에 따라 생존자 수를 비교해보자.\n",
    "\n",
    "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1689cb25708>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 비교적 여성의 생존률이 높다.\n",
    "# 그래프로 이를 다시 한 번 확인해보자.\n",
    "\n",
    "sns.barplot(x='Sex', y='Survived', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x168a4c54808>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 부자와 가난한 사람 간의 생존 확률을 비교해보자. (객실 등급에 따름)\n",
    "\n",
    "sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 나이에 따른 생존률을 알아보자.\n",
    "\n",
    "def get_category(age) :\n",
    "    cat = ''\n",
    "    if age <= -1 : cat = 'Unknown'\n",
    "    elif age <= 5 : cat = 'Baby'\n",
    "    elif age <= 12 : cat = 'Child'\n",
    "    elif age <= 18 : cat = 'Teenager'\n",
    "    elif age <= 25 : cat = 'Student'\n",
    "    elif age <= 35 : cat = 'Young Adult'\n",
    "    elif age <= 60 : cat = 'Adult'\n",
    "    else : cat = 'Elderly'\n",
    "        \n",
    "    return cat\n",
    "\n",
    "# 막대그래프의 크기 figure를 더 크게 설정\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# X축의 값을 순차적으로 표시하기 위한 설정\n",
    "group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Eldery']\n",
    "\n",
    "titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))\n",
    "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)\n",
    "titanic_df.drop('Age_cat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name  Sex   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris    1  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    0  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina    0  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    0  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry    1  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare  Cabin  Embarked  \n",
       "0         A/5 21171   7.2500      7         3  \n",
       "1          PC 17599  71.2833      2         0  \n",
       "2  STON/O2. 3101282   7.9250      7         3  \n",
       "3            113803  53.1000      2         3  \n",
       "4            373450   8.0500      7         3  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 지금까지의 분석을 통해 Sex, Age, PClass 등이 생존을 좌웅하는 주요 피처임을 확인할 수 있었다.\n",
    "# 남아있는 문자열 카테고리 피처를 숫자형 카테고리 피처로 변환하자.\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_features(dataDF) :\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features :\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "titanic_df = encode_features(titanic_df)\n",
    "titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여태까지 피처를 가공한 내역을 정리하고 이를 함수로 만들어 쉽게 재사용하도록 함\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행. \n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin','Sex','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survived 칼럼을 드롭해 피처 데이터 세트를 만들자.\n",
    "\n",
    "#원본 데이터 재로딩, 핖처 데이터 세트와 레이블 데이터 세트 추출\n",
    "titanic_df = pd.read_csv('./data/titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "X_titanic_df = transform_features(X_titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df,\n",
    "                                                    test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도: 0.7877\n",
      "RandomForestClassifier 정확도:0.8547\n",
      "LogisticRegression 정확도: 0.8492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korea_1\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# 여러 모델들로 직접 생존자를 예측해보자.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 결정트리, Random Forest, 로지스틱 회귀를 위한 사이킷런 Classifier 클래스 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "# DecisionTreeClassifier 학습/예측/평가\n",
    "dt_clf.fit(X_train , y_train)\n",
    "dt_pred = dt_clf.predict(X_test)\n",
    "print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "\n",
    "# RandomForestClassifier 학습/예측/평가\n",
    "rf_clf.fit(X_train , y_train)\n",
    "rf_pred = rf_clf.predict(X_test)\n",
    "print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# LogisticRegression 학습/예측/평가\n",
    "lr_clf.fit(X_train , y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7542\n",
      "교차 검증 1 정확도: 0.7809\n",
      "교차 검증 2 정확도: 0.7865\n",
      "교차 검증 3 정확도: 0.7697\n",
      "교차 검증 4 정확도: 0.8202\n",
      "평균 정확도: 0.7823\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증을 사용해보자. (KFold)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def exec_kfold(clf, folds=5):\n",
    "    # 폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한  리스트 객체 생성.\n",
    "    kfold = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    \n",
    "    # KFold 교차 검증 수행. \n",
    "    for iter_count , (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
    "        # X_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]\n",
    "        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "        # Classifier 학습, 예측, 정확도 계산 \n",
    "        clf.fit(X_train, y_train) \n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        scores.append(accuracy)\n",
    "        print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "    # 5개 fold에서의 평균 정확도 계산. \n",
    "    mean_score = np.mean(scores)\n",
    "    print(\"평균 정확도: {0:.4f}\".format(mean_score)) \n",
    "# exec_kfold 호출\n",
    "exec_kfold(dt_clf, folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 0 정확도: 0.7430\n",
      "교차 검증 1 정확도: 0.7753\n",
      "교차 검증 2 정확도: 0.7921\n",
      "교차 검증 3 정확도: 0.7865\n",
      "교차 검증 4 정확도: 0.8427\n",
      "평균 정확도: 0.7879\n"
     ]
    }
   ],
   "source": [
    "# 교차 검증 - cross_val_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dt_clf, X_titanic_df , y_titanic_df , cv=5)\n",
    "for iter_count,accuracy in enumerate(scores):\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 하이퍼 파라미터 : {'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도: 0.7992\n",
      "테스트 세트에서의 DecisionTreeClassifier 정확도 : 0.8715\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':[2,3,5,10],\n",
    "             'min_samples_split':[2,3,5], 'min_samples_leaf':[1,5,8]}\n",
    "\n",
    "grid_dclf = GridSearchCV(dt_clf , param_grid=parameters , scoring='accuracy' , cv=5)\n",
    "grid_dclf.fit(X_train , y_train)\n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터 :',grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "dpredictions = best_dclf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , dpredictions)\n",
    "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
